"""
Utils functions for tabular diffusion model training and sampling.
"""
import os
import numpy as np
import pandas as pd

from typing import Optional


REPO_DIR = os.environ.get("REPO_DIR")
TDDPM_DIR = os.path.join(REPO_DIR, "tab-ddpm")

import sys
sys.path.insert(0, TDDPM_DIR)
sys.path.insert(0, os.path.join(TDDPM_DIR, "scripts"))

import lib
from scripts.sample import sample
from scripts.train import *

def generate_sample(
    pipeline_config_path: str,
    ckpt_path: Optional[str] = None,
    pipeline_dict_path: Optional[str] = None,
    num_samples: Optional[int] = None,
    batch_size: Optional[int] = None,
    temp_parent_dir: str = "ddpm_sample_test",
    device: str = "cuda:0",
    seed: Optional[int] = None,
):
    """
    Generate synthetic samples from a trained tab-ddpm checkpoint.
    - pipeline_config_path: path to the pipeline config file.
        - e.g. path/to/tab-ddpm/exp/adult/ddpm_cb_best/config.toml
    - ckpt_path: path to the checkpoint
        - e.g. /path/to/tab-ddpm/exp/adult/ddpm_cb_best/model.pt
    - pipeline_dict_path: path to the preprocessing pipelines dictionary. Set as None if constructing pipelines from scratch (training data).
        - e.g. /path/to/tab-ddpm/exp/adult/ddpm_cb_best/pipeline_dict.joblib
    - num_samples, batch_size, device will be used to replace the sampling configurations
    - temp_parent_dir: the directory to store the generated samples temporarily, not necessarily the ckpt_path

    The generated samples will be stored in temp_parent_dir as X_cat/num_train.npy and y_train.npy. The sample dir will be returned.

    Example:
    >>> ckpt_path = "/path/to/tab-ddpm/exp/adult/ddpm_cb_best/model.pt"
    >>> num_samples = 1000
    >>> batch_size = num_samples
    >>> device = "cuda:0"
    >>> generate_sample(
    >>>     pipeline_config_path=os.path.join(ckpt_path, "config.toml"),
    >>>     ckpt_path=ckpt_path,
    >>>     num_samples=num_samples,
    >>>     batch_size=batch_size,
    >>>     device=device,
    >>> )
    """

    # # Create parent dir to save the result, remove if already exists
    # if os.path.exists(temp_parent_dir):
    #     shutil.rmtree(temp_parent_dir)
    # os.makedirs(temp_parent_dir)

    # Create parent dir to save the result, overwirte if already exists
    if not os.path.exists(temp_parent_dir):
        os.makedirs(temp_parent_dir)

    parent_dir = temp_parent_dir
    raw_config = lib.load_config(pipeline_config_path)

    raw_config["sample"]["num_samples"] = num_samples
    raw_config["sample"]["batch_size"] = batch_size
    raw_config["parent_dir"] = parent_dir
    raw_config["real_data_path"] = os.path.join(TDDPM_DIR, raw_config["real_data_path"])
    raw_config["device"] = device

    sample(
        num_samples=raw_config["sample"]["num_samples"],
        batch_size=raw_config["sample"]["batch_size"],
        disbalance=raw_config["sample"].get("disbalance", None),
        **raw_config["diffusion_params"],
        parent_dir=raw_config["parent_dir"],
        real_data_path=raw_config["real_data_path"],
        model_path=ckpt_path,
        pipeline_dict_path=pipeline_dict_path,
        model_type=raw_config["model_type"],
        model_params=raw_config["model_params"],
        T_dict=raw_config["train"]["T"],
        num_numerical_features=raw_config["num_numerical_features"],
        device=raw_config["device"],
        seed=seed,
    )

    return temp_parent_dir


def train_tabddpm(
    pipeline_config_path: str,
    real_data_dir: Optional[str] = None,
    ckpt_path: Optional[str] = None,
    pipeline_dict_path: Optional[str] = None,
    steps: Optional[int] = None,
    lr: Optional[float] = None,
    batch_size: Optional[float] = None,
    temp_parent_dir: str = "ddpm_train_asset",
    device: str = "cuda:0",
    seed: Optional[int] = None,
):
    """
    Train tabular diffusiom model (tabddpm) from a checkpoint.
    - pipeline_config_path: path to the pipeline config file.
        - e.g. path/to/tab-ddpm/exp/adult/ddpm_cb_best/config.toml
        - this could be from a configuration of another model -> will save the modified config to temp_parent_dir
        - or could be the one generated by tabddpm fine-tuning with machinea learning efficiency -> probably better set temp_parent_dir to the one containing config.toml
    - ckpt_path: path to the model checkpoint
        - e.g. /path/to/tab-ddpm/exp/adult/ddpm_cb_best/model.pt
    - real_data_dir, steps, lr, batch_size, device will be used to replace the training configurations. If not provided, will use the one present in TOML file.
    - pipeline_dict_path: path to the preprocessing pipelines dictionary. Set as None if constructing pipelines from scratch (training data).
        - e.g. /path/to/tab-ddpm/exp/adult/ddpm_cb_best/pipeline_dict.joblib
    - temp_parent_dir: the directory to store the generated samples temporarily, not necessarily the ckpt_path

    real_data_dir should has the following structure:
    - info.json
    - X/y_{num/cat}_{train/val/test}.npy

    The training asset (ckpt, loss, other stuff) will be saved in the temp_paranet_dir. The training asset dir will be returned.

    Example:
    >>> ckpt_path = "/path/to/tab-ddpm/exp/adult/ddpm_cb_best/model.pt"
    >>> steps = 1000
    >>> lr = None
    >>> batch_size = None
    >>> temp_parent_dir = "ddpm_train_asset"
    >>> device = "cuda:0"
    >>> train_dir = train_tabddpm(
    >>>     pipeline_config_path=os.path.join(ckpt_path, "config.toml"),
    >>>     ckpt_path=ckpt_path,
    >>>     steps=steps,
    >>>     lr=lr,
    >>>     batch_size=batch_size,
    >>>     temp_parent_dir=temp_parent_dir,
    >>>     device=device,
    >>>     use_ckpt=True
    >>> )
    """

    # # Create parent dir to save the result, remove if already exists
    # if os.path.exists(temp_parent_dir):
    #     shutil.rmtree(temp_parent_dir)
    # os.makedirs(temp_parent_dir)

    # Create parent dir to save the result, overwirte if already exists
    if not os.path.exists(temp_parent_dir):
        os.makedirs(temp_parent_dir)

    parent_dir = temp_parent_dir

    raw_config = lib.load_config(pipeline_config_path)

    raw_config["parent_dir"] = parent_dir
    raw_config["real_data_path"] = (
        os.path.join(TDDPM_DIR, raw_config["real_data_path"])
        if real_data_dir is None
        else real_data_dir
    )
    raw_config["device"] = device

    if steps is not None:
        raw_config["train"]["main"]["steps"] = steps
    if lr is not None:
        raw_config["train"]["main"]["lr"] = lr
    if batch_size is not None:
        raw_config["train"]["main"]["batch_size"] = batch_size

    # save the new modified configuration file to temp_parent_dir
    lib.dump_config(raw_config, os.path.join(temp_parent_dir, "config.toml"))

    train(
        **raw_config["train"]["main"],
        **raw_config["diffusion_params"],
        parent_dir=raw_config["parent_dir"],
        real_data_path=raw_config["real_data_path"],
        model_type=raw_config["model_type"],
        model_params=raw_config["model_params"],
        model_path=ckpt_path,
        pipeline_dict_path=pipeline_dict_path,
        T_dict=raw_config["train"]["T"],
        num_numerical_features=raw_config["num_numerical_features"],
        device=device,
        seed=seed,
    )

    return temp_parent_dir


